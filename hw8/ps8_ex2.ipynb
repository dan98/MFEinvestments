{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 21 10:06:47 2020\n",
    "\n",
    "@author: williammartin\n",
    "\"\"\"\n",
    "\n",
    "# import standard libraries\n",
    "import numpy as np\n",
    "# import third-party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import wrds\n",
    "# import local libraries\n",
    "\n",
    "plt.close('all')\n",
    "DOWNLOAD = False\n",
    "LOAD_CACHE = True\n",
    "\n",
    "class Stock:\n",
    "    \n",
    "    def __init__(self, permno, df):\n",
    "        self.permno = permno\n",
    "        self.df = df\n",
    "        # compute market capitalization\n",
    "        self.df['mcap'] = self.df['shrout'] * self.df['prc'].abs()\n",
    "        \n",
    "    def computeAverageReturn(self):\n",
    "        \"\"\"\n",
    "        For each stock and each month t, calculate the average \n",
    "        return of the stock between month t-12 and t-2.\n",
    "        \n",
    "        We assume there are no jumps of months and apply \n",
    "        the average over the integer index and not the datetime.\n",
    "        \"\"\"\n",
    "        ret_lag = self.df[['ret']].shift(2)\n",
    "        mean_ret = ret_lag.rolling(10+1).mean()\n",
    "        mean_ret = mean_ret.rename(columns = {'ret': 'mean_ret'})\n",
    "        self.df = pd.concat([self.df, mean_ret], axis = 1)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    start = '1970-01-01'\n",
    "    end = '2019-12-31'\n",
    "\n",
    "    if DOWNLOAD:\n",
    "        \n",
    "        # connect to db\n",
    "        db = wrds.Connection(wrds_username = 'wmartin')\n",
    "        # db.create_pgpass_file()\n",
    "\n",
    "        # get risk free\n",
    "        rf = db.raw_sql(\"select mcaldt,tmytm \"\n",
    "                        \"from crsp.tfz_mth_rf \"           \n",
    "                        \"where kytreasnox = 2000001 \"\n",
    "                        \"and mcaldt>='{}'\"\n",
    "                        \"and mcaldt<='{}'\".format(start, end), \n",
    "                        date_cols = ['mcaldt'])\n",
    "        \n",
    "        # get crsp value-weighted idnex return\n",
    "        crsp_index = db.raw_sql(\"select date,vwretd \"\n",
    "                                \"from crsp.msi \"\n",
    "                                \"where date>='{}'\"\n",
    "                                \"and date<='{}'\".format(start, end), \n",
    "                                date_cols = ['date'])\n",
    "        \n",
    "        # get crsp stock event\n",
    "        crsp_stock = db.raw_sql(\"select a.permno, a.date, \"\n",
    "                                \"b.shrcd, b.exchcd, a.ret, a.shrout, a.prc \"\n",
    "                                \"from crsp.msf as a \"\n",
    "                                \"left join crsp.msenames as b \" \n",
    "                                \"on a.permno=b.permno \" \n",
    "                                \"and b.namedt<=a.date \" \n",
    "                                \"and a.date<=b.nameendt \"\n",
    "                                \"where a.date between '{}' and '{}' \"\n",
    "                                \"and b.exchcd in (1, 2) \"\n",
    "                                \"and b.shrcd in (10, 11) \".format(start, end), \n",
    "                                date_cols=['date']) \n",
    "        \n",
    "        crsp_stock = crsp_stock.drop(columns = ['shrcd', 'exchcd'])\n",
    "        \n",
    "        # write to csv raw\n",
    "        rf.to_csv('rf.csv')\n",
    "        crsp_index.to_csv('crsp_index.csv')\n",
    "        crsp_stock.to_csv('crsp_stock.csv')\n",
    "\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # read locally\n",
    "        rf = pd.read_csv('rf.csv', usecols = [1, 2])\n",
    "        rf['mcaldt'] = pd.to_datetime(rf['mcaldt'])\n",
    "        \n",
    "        crsp_index = pd.read_csv('crsp_index.csv', usecols = [1, 2])\n",
    "        crsp_index['date'] = pd.to_datetime(crsp_index['date'])\n",
    "        \n",
    "        crsp_stock = pd.read_csv('crsp_stock.csv', usecols = [1, 2, 3, 4, 5])\n",
    "        crsp_stock['date'] = pd.to_datetime(crsp_stock['date'])\n",
    "    \n",
    "    # clean rf\n",
    "    rf = rf.rename(columns = {'mcaldt': 'date', 'tmytm': 'rf'})\n",
    "    \n",
    "    # clean data a bit\n",
    "    rf = rf.set_index('date')\n",
    "    crsp_index = crsp_index.set_index('date')\n",
    "    crsp_stock = crsp_stock.set_index('date')\n",
    "    \n",
    "    # floatify data\n",
    "    crsp_stock['permno'] = \\\n",
    "        crsp_stock['permno'].astype(int)\n",
    "        \n",
    "    # correct rf to monhtly returns\n",
    "    rf = rf.applymap(lambda x: np.exp(x/12/100) - 1)\n",
    "    \n",
    "    # read fama data\n",
    "    mom = pd.read_csv('F-F_Momentum_Factor.csv', skiprows = 12, index_col = 0)\n",
    "    mom = mom.loc[:'201912']\n",
    "    mom = mom.rename(columns = {'Mom   ': 'Mom'})\n",
    "    fama = pd.read_csv('F-F_Research_Data_5_Factors_2x3.csv', skiprows = 3, index_col = 0)\n",
    "    fama = fama.loc[:'201912']\n",
    "    # set index of fama website to datetime (end of month)\n",
    "    mom.index = (pd.to_datetime(mom.index, format = '%Y%m')+MonthEnd(1))\n",
    "    fama.index = (pd.to_datetime(fama.index, format = '%Y%m')+MonthEnd(1))\n",
    "    # filter date from mom and fama\n",
    "    mom = mom.loc[start:end, :]\n",
    "    fama = fama.loc[start:end, :]\n",
    "    \n",
    "    # change columns types\n",
    "    mom = mom.astype(float)\n",
    "    fama = fama.astype(float)\n",
    "    \n",
    "    # divide fama and mom by 100\n",
    "    fama /= 100\n",
    "    mom /= 100\n",
    "    \n",
    "    # split crsp_stock by stock\n",
    "    crsp_stock_grouped = crsp_stock.groupby('permno')\n",
    "    # create stocks from data\n",
    "    stocks = {}\n",
    "    for permno, df in crsp_stock_grouped:\n",
    "        df = df.drop(columns = ['permno'])\n",
    "        df = df.sort_index()\n",
    "        # do a forward fill and backward fill if missing values\n",
    "        # df = df.dropna(how = 'any', axis = 0)\n",
    "        #df = df.fillna(method = 'ffill')\n",
    "        #df = df.fillna(method = 'bfill')\n",
    "        stocks[permno] = Stock(permno, df)\n",
    "        \n",
    "        \n",
    "# =============================================================================\n",
    "# (b)\n",
    "# =============================================================================\n",
    "        \n",
    "    if not LOAD_CACHE: \n",
    "    \n",
    "        # compute average returns as written in the exercise sheet\n",
    "        for _, stock in stocks.items():\n",
    "            stock.computeAverageReturn()\n",
    "            \n",
    "        # create a dataframe containing the average returns of all stocks\n",
    "        mean_ret_stocks = pd.DataFrame()\n",
    "        for permno, stock in stocks.items():\n",
    "            temp = stock.df[['mean_ret']].rename(columns = {'mean_ret': permno})\n",
    "            mean_ret_stocks = pd.concat([mean_ret_stocks, temp], axis = 1)\n",
    "            \n",
    "        mean_ret_stocks.to_csv('mean_ret_stocks.csv')\n",
    "        \n",
    "        # construct dataframe of all returns of all stocks\n",
    "        ret_stocks = pd.DataFrame()\n",
    "        for permno, stock in stocks.items():\n",
    "            temp = stock.df[['ret']].rename(columns = {'ret': permno})\n",
    "            ret_stocks = pd.concat([ret_stocks, temp], axis = 1)\n",
    "            \n",
    "        ret_stocks.to_csv('ret_stocks.csv')\n",
    "        \n",
    "        # construct dataframe of all market caps\n",
    "        mcap_stocks = pd.DataFrame()\n",
    "        for permno, stock in stocks.items():\n",
    "            temp = stock.df[['mcap']].rename(columns = {'mcap': permno})\n",
    "            mcap_stocks = pd.concat([mcap_stocks, temp], axis = 1)\n",
    "            \n",
    "        mcap_stocks.to_csv('mcap_stocks.csv')\n",
    "        \n",
    "    else: # faster if saved in csv\n",
    "        \n",
    "        mean_ret_stocks = pd.read_csv('mean_ret_stocks.csv', index_col = 'date')\n",
    "        mean_ret_stocks.index = pd.to_datetime(mean_ret_stocks.index)\n",
    "        mean_ret_stocks.columns = mean_ret_stocks.columns.astype(int)\n",
    "\n",
    "        # put mean_ret back in stocks\n",
    "        for permno in mean_ret_stocks:\n",
    "            stocks[permno].df['mean_ret'] = mean_ret_stocks[permno]\n",
    "            \n",
    "        ret_stocks = pd.read_csv('ret_stocks.csv', index_col = 'date')\n",
    "        ret_stocks.index = pd.to_datetime(ret_stocks.index)\n",
    "        ret_stocks.columns = ret_stocks.columns.astype(int)\n",
    "        \n",
    "        mcap_stocks = pd.read_csv('mcap_stocks.csv', index_col = 'date')\n",
    "        mcap_stocks.index = pd.to_datetime(mcap_stocks.index)\n",
    "        mcap_stocks.columns = mcap_stocks.columns.astype(int)\n",
    "            \n",
    "    # drop months where there is nothng (due to shift and rolling methods)\n",
    "    mean_ret_stocks = mean_ret_stocks.dropna(how = 'all', axis = 0)\n",
    "    # in case\n",
    "    ret_stocks = ret_stocks.dropna(how = 'all', axis = 0)\n",
    "    mcap_stocks = mcap_stocks.dropna(how = 'all', axis = 0)\n",
    "        \n",
    "    # in each month, sort the stocks into 10 deciles based on that average return\n",
    "    # we omit stocks that were not traded when going through months\n",
    "    # duplicates = False\n",
    "    mean_ret_deciles = mean_ret_stocks.apply(lambda x: 1 + pd.qcut(x, \n",
    "                                                                   10, \n",
    "                                                                   labels = False,\n",
    "                                                                   duplicates = 'drop'), \n",
    "                                             axis = 1)\n",
    "    \n",
    "    # a quick check using value counts over each row tells us that \n",
    "    # the binning was done correctly\n",
    "    \n",
    "    # truncate ret_stocks\n",
    "    ret_stocks = ret_stocks.iloc[12:]\n",
    "    mcap_stocks = mcap_stocks.iloc[12:]\n",
    "    \n",
    "    # create value-weighted returns every month based on 10 deciles\n",
    "    vw_returns = pd.DataFrame(index = mean_ret_deciles.index,\n",
    "                              columns = list(range(1, 11)))\n",
    "    \n",
    "    # fill vw_returns\n",
    "    # go over all bins\n",
    "    for b in vw_returns.columns:\n",
    "        returns_b = ret_stocks.mask(mean_ret_deciles != float(b), np.nan)\n",
    "        mcaps_b = mcap_stocks.mask(mean_ret_deciles != float(b), np.nan)\n",
    "        returns_b = returns_b.dropna(how = 'all')\n",
    "        mcaps_b = mcaps_b.dropna(how = 'all')        \n",
    "        weights_b = mcaps_b.apply(lambda row: row/row.sum(), axis = 1)\n",
    "        vw_returns_b = pd.DataFrame((weights_b*returns_b)\\\n",
    "                                    .sum(axis = 1)/weights_b.sum(axis = 1))\n",
    "        vw_returns[b] = vw_returns_b\n",
    "        \n",
    "    # Compute the returns on a zero-cost portfolio that \n",
    "    # goes long in the group with the highest past returns \n",
    "    # and short in the group with the lowest past returns\n",
    "    zero_cost_returns = vw_returns[10] - vw_returns[1]\n",
    "    \n",
    "    # get expected zero cost returns\n",
    "    rf_fama = fama.iloc[12:]['RF']\n",
    "\n",
    "    #Compute the alpha of this strategy with respect to the SMB and HML factors.\n",
    "    # get same index in fama as in zero_cost_returns\n",
    "    smb_hml = fama.iloc[12:][['Mkt-RF', 'SMB', 'HML']]\n",
    "    smb_hml_mom = pd.concat([smb_hml,  mom.iloc[12:]], axis = 1) \n",
    "    \n",
    "    # do a linear regression\n",
    "    regr_fama = LinearRegression()\n",
    "    regr_fama = regr_fama.fit(smb_hml, zero_cost_returns)\n",
    "    alpha_fama = regr_fama.intercept_\n",
    "    beta_fama = regr_fama.coef_\n",
    "    \n",
    "    regr_fama_mom = LinearRegression()\n",
    "    regr_fama_mom = regr_fama_mom.fit(smb_hml_mom, zero_cost_returns)\n",
    "    alpha_fama_mom = regr_fama_mom.intercept_\n",
    "    beta_fama_mom = regr_fama_mom.coef_\n",
    "    \n",
    "    # alpha_fama = 0.009851730287095881\n",
    "    # alpha_fama_mom = -0.0037760959322449853\n",
    "    # beta_fama = array([-0.38343795,  0.02467195, -0.62787765])\n",
    "    # beta_fama_mom = array([-0.04944137,  0.0455642 , -0.03081603,  1.560502  ])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (12, 6))\n",
    "    zero_cost_returns.plot(ax = ax)\n",
    "    ax.set_ylabel('returns')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# (c)\n",
    "# =============================================================================\n",
    "    \n",
    "    if not LOAD_CACHE:\n",
    "        \n",
    "        # get lagged market capitalization of all stocks in one dataframe\n",
    "        mcap_lag_stocks = pd.DataFrame()\n",
    "        for permno, stock in stocks.items():\n",
    "                temp = stock.df[['mcap']].shift(1).rename(columns = {'mcap': permno})\n",
    "                mcap_lag_stocks = pd.concat([mcap_lag_stocks, temp], axis = 1)\n",
    "                \n",
    "        mcap_lag_stocks.to_csv('mcap_lag_stocks.csv')\n",
    "                \n",
    "    else: # faster if read from csv\n",
    "        mcap_lag_stocks = pd.read_csv('mcap_lag_stocks.csv', index_col = 'date')\n",
    "        mcap_lag_stocks.index = pd.to_datetime(mcap_lag_stocks.index)\n",
    "        mcap_lag_stocks.columns = mcap_lag_stocks.columns.astype(int)\n",
    "        \n",
    "    # drop months where there is nothng (due to shift method)\n",
    "    mcap_lag_stocks = mcap_lag_stocks.dropna(how = 'all', axis = 0)  \n",
    "    \n",
    "    # in each month, sort the stocks into 2 deciles based on market capitalization\n",
    "    # we omit stocks that were not traded when going through months\n",
    "    # duplicates = False\n",
    "    mcap_stocks_deciles = mcap_lag_stocks.apply(lambda x: 1 + pd.qcut(x, \n",
    "                                                                      2, \n",
    "                                                                      labels = False,\n",
    "                                                                      duplicates = 'drop'), \n",
    "                                                axis = 1) \n",
    "    \n",
    "    # create value-weighted returns every month based on 2 deciles\n",
    "    vw_returns_bis = pd.DataFrame(index = mcap_stocks_deciles.index,\n",
    "                                  columns = list(range(1, 3)))\n",
    "    \n",
    "    # fill vw_returns according to mcap binning\n",
    "    # go over all 2 bins\n",
    "    for b in vw_returns_bis.columns:\n",
    "        returns_b = ret_stocks.mask(mcap_stocks_deciles != float(b), np.nan)\n",
    "        mcaps_b = mcap_stocks.mask(mcap_stocks_deciles != float(b), np.nan)\n",
    "        returns_b = returns_b.dropna(how = 'all')\n",
    "        mcaps_b = mcaps_b.dropna(how = 'all')        \n",
    "        weights_b = mcaps_b.apply(lambda row: row/row.sum(), axis = 1)\n",
    "        vw_returns_b = pd.DataFrame((weights_b*returns_b)\\\n",
    "                                    .sum(axis = 1)/weights_b.sum(axis = 1))\n",
    "        vw_returns_bis[b] = vw_returns_b\n",
    "\n",
    "    # Compute the returns on a zero-cost portfolio that \n",
    "    # goes long in the group with the highest past returns \n",
    "    # and short in the group with the lowest past returns\n",
    "    zero_cost_returns_bis = - vw_returns_bis[2] + vw_returns_bis[1]\n",
    "    zero_cost_returns_bis = zero_cost_returns_bis.dropna(how = 'all', axis = 0)\n",
    "    \n",
    "    # do a linear regression\n",
    "    regr_fama = LinearRegression()\n",
    "    regr_fama = regr_fama.fit(smb_hml, zero_cost_returns_bis)\n",
    "    alpha_fama_bis = regr_fama.intercept_\n",
    "    beta_fama_bis = regr_fama.coef_\n",
    "    \n",
    "    regr_fama_mom = LinearRegression()\n",
    "    regr_fama_mom = regr_fama_mom.fit(smb_hml_mom, zero_cost_returns_bis)\n",
    "    alpha_fama_mom_bis = regr_fama_mom.intercept_\n",
    "    beta_fama_mom_bis = regr_fama_mom.coef_\n",
    "    \n",
    "    # alpha_fama_bis = 0.00960077667829191\n",
    "    # alpha_fama_mom_bis = 0.011508877741353155\n",
    "    # beta_fama_bis = array([0.13404236, 1.1668894 , 0.30822139])\n",
    "    # beta_fama_mom_bis = array([ 0.08727781,  1.16396417,  0.22462377, -0.2184938 ])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (12, 6))\n",
    "    zero_cost_returns_bis.plot(ax = ax)\n",
    "    ax.set_ylabel('returns')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
